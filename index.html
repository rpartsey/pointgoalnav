<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Is Mapping Necessary for Realistic PointGoal Navigation?</title>
    <link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet" type="text/css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet"
          integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" crossorigin="anonymous">
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"
            integrity="sha384-ka7Sk0Gln4gmtz2MlQnikT1wXgYsOg+OMhuP+IlRH9sENBO0LRn5q+8nbTov4+1p"
            crossorigin="anonymous"></script>
    <link href="main/main.css" rel="stylesheet">
    <script src="https://kit.fontawesome.com/dd945917ca.js" crossorigin="anonymous"></script>


</head>
<body>
<div class="jumbotron jumbotron-fluid">
    <div class="row justify-content-center bg-light border-bottom fixed-top">
        <div class="col-sm-8">
            <nav class="navbar navbar-expand-lg navbar-light bg-light">
                <button class="navbar-toggler shadow-none border-0 align-items-end" type="button"
                        data-bs-toggle="collapse"
                        data-bs-target="#navbarSupportedContent"
                        aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
                    <span class="navbar-toggler-icon"></span>
                </button>
                <div class="collapse navbar-collapse" id="navbarSupportedContent">

                    <ul class="navbar-nav me-auto ps-3">
                        <li class="nav-item d-sm-none d-none d-md-none d-lg-block">
                            <a class="navbar-brand" href="https://cvpr2022.thecvf.com/">
                                <img class="conference" src="img/cvpr22.png">
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="#about">About</a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="#leaderboard">Leaderboard</a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="#sim2real">Sim2real</a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="#results">Results</a>
                        </li>
                    </ul>
                </div>
                <a href="https://ucu.edu.ua/en/" class="ps-2">
                    <img class="logo d-sm-none d-none d-md-none d-lg-block" src="img/ucu.png">
                </a>
                <a href="https://https://www.gatech.edu" class="ps-2">
                    <img class="logo d-sm-none d-none d-md-none d-lg-block" src="img/ga.png">
                </a>
                <a href="https://ai.facebook.com/" class="ps-2">
                    <img class="logo d-sm-none d-none d-md-none d-lg-block" src="img/meta.png">
                </a>
            </nav>
        </div>
    </div>
    <div class="container-fluid bg-light m">
        <div class="row justify-content-center" id="about">
            <div class="col-sm-8 pt-5">
                <h2 class="text-center pt-5 pb-3">Is Mapping Necessary for Realistic PointGoal Navigation?</h2>
                <div class="row justify-content-center g-1">
                    <div class="col-md-2 text-center">
                        <a href="https://apps.ucu.edu.ua/ruslan-partsey/" class="text-decoration-none"
                           target="_blank">
                            <img src="img/ruslan_partsey.jpg"
                                 class="rounded-circle img-fluid d-sm-none d-none d-md-block">
                            <small>Ruslan Partsey<sup>1</sup></small>
                        </a>
                    </div>
                    <div class="col-md-2 text-center">
                        <a href="https://wijmans.xyz" class="text-decoration-none" target="_blank">
                            <img src="img/erik_wijmans.jpg"
                                 class="rounded-circle img-fluid d-sm-none d-none d-md-block">
                            <small>Erik Wijmans<sup>2,3</sup></small>
                        </a>
                    </div>
                    <div class="col-md-2 text-center">
                        <a href="http://naoki.io" class="text-decoration-none" target="_blank">
                            <img src="img/naoki_yokoyama.jpeg"
                                 class="rounded-circle img-fluid d-sm-none d-none d-md-block">
                            <small>Naoki Yokoyama<sup>2</sup></small>
                        </a>
                    </div>
                    <div class="col-md-2 text-center">
                        <a href="https://apps.ucu.edu.ua/en/oles-dobosevych/" class="text-decoration-none"
                           target="_blank">
                            <img src="img/oles_dobosevych.jpeg"
                                 class="rounded-circle img-fluid d-sm-none d-none d-md-block">
                            <small>Oles Dobosevych<sup>1</sup></small>
                        </a>
                    </div>
                    <div class="col-md-2 text-center">
                        <a href="https://www.cc.gatech.edu/~dbatra/" class="text-decoration-none" target="_blank">
                            <img src="img/dhruv_batra.jpeg"
                                 class="rounded-circle img-fluid d-sm-none d-none d-md-block">
                            <small>Dhruv Batra<sup>2,3</sup></small>
                        </a>
                    </div>
                    <div class="col-md-2 text-center">
                        <a href="https://research.facebook.com/people/maksymets-oleksandr/"
                           class="text-decoration-none"
                           target="_blank">
                            <img src="img/oleksandr_maksymets.jpg"
                                 class="rounded-circle img-fluid d-sm-none d-none d-md-block">
                            <small>Oleksandr Maksymets<sup>3</sup></small>
                        </a>
                    </div>
                </div>
                <h6 class="text-center pt-3">
                    <sup>1</sup>Ukrainian Catholic University &nbsp;&nbsp;
                    <sup>2</sup>Georgia&nbsp;Institute&nbsp;of&nbsp;Technology &nbsp;&nbsp;
                    <sup>3</sup>Meta AI
                </h6>
                <h6 class="text-center">
                    <a class="btn btn-dark"
                       href="https://github.com/rpartsey/pointgoal-navigation"
                       role="button" target="_blank">
									<span class="icon">
										<i class="fab fa-github fa-fw"></i>
									</span>
                        <span>GitHub</span>
                    </a>
                    <a class="btn btn-dark" href="#" role="button" target="_blank">
                        <span class="icon"><i class="ai ai-arxiv fa-fw"></i></span>
                        <span>arXiv</span>
                    </a>
                </h6>
            </div>
        </div>
        <div class="container-fluid pt-3">
            <div class="section">
                <div class="row justify-content-center">
                    <div class="col-sm-8">
                        <p>Can an autonomous agent navigate in a new environment without building an explicit map?</p>
                        <p>For the task of PointGoal navigation (Go to $\Delta x$, $\Delta y$) under idealized
                            settings (no RGB-D and actuation noise, perfect GPS+Compass), the answer is a clear `yes`
                            &mdash; map-less neural models composed of task-agnostic components (CNNs and RNNs) trained
                            with
                            large-scale reinforcement learning achieve 100% Success on a standard dataset
                            (Gibson [<a class="text-decoration-none" href="#ramakrishnan2021habitat">1</a>]). However,
                            for
                            PointNav in a
                            <it>realistic</it>
                            setting (RGB-D and actuation noise, no GPS+Compass), this is
                            an open question; one we tackle in this paper. The strongest published result for this task
                            is
                            71.7% Success [<a class="text-decoration-none" href="#zhao2021the">2</a>]<sup>1</sup>.
                        </p>

                        <p>First, we identify the main (perhaps, only) cause of the drop in performance: absence of
                            GPS+Compass. An agent with perfect GPS+Compass faced with RGB-D sensing and actuation noise
                            achieves 99.8% Success (Gibson-v2 val). This suggests that (to paraphrase a meme) robust
                            visual
                            odometry is all we need for realistic PointNav; if we can achieve that, we can ignore the
                            sensing and actuation noise.</p>

                        <p>With that as our operating hypothesis, we scale dataset and model size, and develop
                            human-annotation-free data-augmentation techniques to train models for visual odometry. We
                            advance the state of art on the Habitat Realistic PointNav Challenge from 71% to 94% Success
                            (+23, 31% relative) and 53% to 74% SPL (+21, 40% relative). While our approach does not
                            saturate
                            or `solve` this dataset, this strong improvement combined with promising zero-shot sim2real
                            transfer
                            (to a LoCoBot) provides evidence consistent with the hypothesis that explicit mapping may
                            not be
                            necessary for navigation, even in a realistic setting.</p>
                        </p>

                        <p><sup>1</sup>According to Habitat Challenge 2020 PointNav benchmark held annually. A
                            concurrent
                            as-yet-unpublished result has reported 91% Success on 2021's benchmark, but we are unable to
                            comment on the details because an
                            associated report is not available.</p>
                    </div>
                </div>
            </div>
            <div class="section pt-5" id="leaderboard">
                <div class="row justify-content-center pt-3">
                    <div class="col-sm-8">
                        <h3 class="text-center">Online Leaderboard</h3>
                        <hr>
                        <a href="https://eval.ai/web/challenges/challenge-page/802/leaderboard/2192"
                           target="_blank">
                            <figure class="figure">

                                <img class="img-fluid" src="img/leaderboard.png">
                                <figcaption class="figure-caption"> Online benchmark test-standard split (retrieved
                                    2021-Nov-16). The work of ‘inspir.ai robotics’ is concurrent unpublished work.
                                </figcaption>
                            </figure>
                        </a>
                    </div>
                </div>
            </div>

            <div class="section pt-5" id="results">
                <div class="row justify-content-center pt-3">
                    <div class="col-sm-8 pb-3">
                        <h3 class="text-center">Qualitative Results</h3>
                        <hr>
                        <div class="dataset">
                            <h4>Gibson 4+ (val)</h4>
                            <div class="video">
                                <iframe src="https://www.youtube.com/embed/videoseries?list=PLOpaOPpuhyVGdV0TiYkLaG-vYwpYmNqU4"
                                        allowfullscreen></iframe>
                            </div>
                            <figure class="figure">
                                <img class="img-fluid pt-3" src="img/gibson.png">
                                <figcaption class="figure-caption">Our best HC 2021 PointNav agent’s navigation
                                    trajectories on Gibson 4+ val scenes (and Gibson-v2 PointGoal navigation episodes)
                                    broken down by geodesic distance between agent’s spawn location and target (on rows)
                                    vs SPL achieved by the agent (on cols).
                                </figcaption>
                            </figure>
                        </div>
                        <div class="dataset pt-5">
                            <h4>Matterport3D (val)</h4>
                            <div class="video">
                                <iframe src="https://www.youtube.com/embed/videoseries?list=PLOpaOPpuhyVHltiNA2WZ4HMGW-NfiDXOs"
                                        allowfullscreen></iframe>
                            </div>
                            <figure class="figure">
                                <img class="img-fluid pt-3" src="img/matterport.png">
                                <figcaption class="figure-caption"> Our best HC 2021 PointNav agent’s navigation
                                    trajectories on MP3D val scenes (and MP3D-v2 PointGoal navigation episodes) broken
                                    down by geodesic distance between agent’s spawn location and target (on rows) vs SPL
                                    achieved by the agent (on cols).
                                </figcaption>
                            </figure>

                        </div>
                        <p class="pt-3">Agent is asked to navigate from blue square to green square. The color of the
                            trajectory
                            changes from dark to light over time (cv2.COLORMAP_WINTER for agent's trajectory,
                            cv2.COLORMAP_AUTUMN for agent's estimate of its trajectory).</p>
                        <p>Navigation videos and top-down maps were generated during two different agent runs, which
                            means
                            other actuation and sensing noise were applied, so the trajectories on video and image may
                            be
                            slightly different.</p>
                        <p>To see navigation metrics for episodes from the playlists above, please, open the video in a
                            separate tab and check the video description.</p>
                    </div>
                </div>
            </div>

            <div class="section pt-5" id="sim2real">
                <div class="row justify-content-center pt-3">
                    <div class="col-sm-8">
                        <h3 class="text-center">Simulation-to-reality Transfer</h3>
                        <hr>
                        <div class="dataset">
                            <h4 id="3d-person-view">3rd-person view</h4>
                            <div class="video2">
                                <iframe src="https://www.youtube.com/embed/videoseries?list=PLOpaOPpuhyVG9jl0DQpJv9mH17Cw00VRM"
                                        allowfullscreen></iframe>
                            </div>
                        </div>
                        <div class="dataset">
                            <h4 id="ros-bag">rosbag videos</h4>
                            <div class="video2">
                                <iframe src="https://www.youtube.com/embed/videoseries?list=PLOpaOPpuhyVG4Oa-_pmq397VjfMN0DEcj"
                                        allowfullscreen></iframe>
                            </div>
                        </div>
                        <p>To see navigation metrics for episodes from the playlists above, please, open the video in a
                            separate tab and check the video description.</p>
                        <div class="dataset">
                            <h4>Reality experiments top-down maps</h4>
                            <img class="img-fluid pt-3" src="img/reality.png">
                        </div>
                    </div>
                </div>
            </div>

            <div class="section">
                <div class="row justify-content-center">
                    <div class="col-sm-8">
                        <h3 class="text-center">References</h3>
                        <hr>
                        <ol>
                            <li id="ramakrishnan2021habitat">Santhosh K. Ramakrishnan, Aaron Gokaslan, Erik Wijmans,
                                Oleksandr Maksymets, Alexander Clegg,
                                John Turner, EricUndersander, Wojciech Galuba, Andrew Westbury, Angel X.
                                Chang, Manolis Savva, Yili Zhao, and Dhruv Batra. Habitat-matterport 3d dataset (hm3d):
                                1000
                                large-scale 3d environ-ments for embodied ai.arXiv preprint arXiv:2109.08238,2021
                            </li>
                            <li id="zhao2021the">Xiaoming Zhao, Harsh Agrawal, Dhruv Batra, and Alexan-der G.
                                Schwing.The
                                surprising effectiveness of visualodometry techniques for embodied pointgoal navigation.
                                InProceedings of the IEEE/CVF International Conference onComputer Vision, pages
                                16127–16136,
                                2021
                            </li>
                        </ol>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script async>
        window.MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']]
            }
        };
    </script>
</body>
</html>
